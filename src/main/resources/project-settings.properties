calculcation of dump files to parse / wiki files in bz2 or gzip file format are accepted                          
doc.file_location=/media/win7/dbfarm/wiki-dumps                                                                   
# file format of dump files                                                                                       
doc.file_type=bz2                                                                                                 
# the batch size indicates how many documents should be stored at a stroke. A higher value should reduce write tim
e but will require more memory                                                                                    
doc.batch_size=500                                                                                                
# maximum number of documents to be read                                                                          
doc.max=10000                                                                                                     
# maximum number of files processed                                                                               
doc.max_files=10000                                                                                               
# document nr offset! will start with with documentnumber provided                                                
doc.start_doc_offset=0                                                                                            
# format of timestamps to parse (wiki-dump date format = preset)                                                  
doc.date_format=yyyy-MM-dd'T'hh:mm:ss'Z'                                                                          
# language of input files (so far only english (en) is supported)                                                 
doc.lang=en                                                                                                       
# project scenario (can be 'V1' or 'V2') so far (case sensitive!!!), check help file for details                  
doc.scenario=V1                                                                                                   
# max lenght of dict terms (longer terms will be ignored!) -> please adjust to database config of dict table (TERM
 VARCHAR(dox.maxTermLength))                                                                                      
doc.maxTermLength=100                                                                                             
# max number of dict terms to be cached in working memory (standard 500Mio, consumes up to 6GB of working memory) 
doc.maxDictCache=500000000                                                                                        
# use valid time (true) or transaction time (false)                                                               
doc.validTime=false                                                                                               
# number of documents after which a report is triggered (long value > 1)                                          
doc.reportLimit=10000                                                                                             
# do not process new documents, which did's are not already stored in the database
doc.ommittNewDocs=false    
# determines wheter document updates should be consiedered, when set to true, documents with same document ids are added when the revid distinguishes from the
# documents in place
doc.updatesInclued=false